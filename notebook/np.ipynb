{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "549e8b26",
   "metadata": {},
   "source": [
    "# CSC173 Activity 01 - Neural Network from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96c777",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96afeefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.typing import NDArray\n",
    "from numpy import float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372fe756",
   "metadata": {},
   "source": [
    "## Define possible activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4700ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: NDArray[float64]) -> NDArray[float64]:\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x: NDArray[float64]) -> NDArray[float64]:\n",
    "    return x * (1 - x)\n",
    "\n",
    "def tanh(x: NDArray[float64]) -> NDArray[float64]:\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(x: NDArray[float64]) -> NDArray[float64]:\n",
    "    return 1 - np.tanh(x) ** 2\n",
    "\n",
    "def relu(x: NDArray[float64]) -> NDArray[float64]:\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x: NDArray[float64]) -> NDArray[float64]:\n",
    "    return (x > 0).astype(float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f63d7",
   "metadata": {},
   "source": [
    "## Select activation functions for hidden and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2514658",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_activation, hidden_activation_derivative = relu, relu_derivative\n",
    "output_activation, output_activation_derivative = sigmoid, sigmoid_derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a166cb0e",
   "metadata": {},
   "source": [
    "## Neural Network Core Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9439e66",
   "metadata": {},
   "source": [
    "### Function for parameter initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3785561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(input_size: int, hidden_size: int, output_size: int) -> dict[str, NDArray[float64]]:\n",
    "    W1: NDArray[float64] = np.random.randn(input_size, hidden_size) * np.sqrt(2. / input_size)      # (input_size × hidden_size)\n",
    "    b1: NDArray[float64] = np.zeros((1, hidden_size))                                               # (1 × hidden_size)\n",
    "    \n",
    "    W2: NDArray[float64] = np.random.randn(hidden_size, output_size) * np.sqrt(2. / hidden_size)    # (hidden_size × output_size)\n",
    "    b2: NDArray[float64] = np.zeros((1, output_size))                                               # (1 × output_size)\n",
    "    \n",
    "    return {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b881917",
   "metadata": {},
   "source": [
    "### Function implementing forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab27b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(\n",
    "    X: NDArray[float64], \n",
    "    parameters: dict[str, NDArray[float64]]\n",
    ") -> tuple[NDArray[float64], dict[str, NDArray[float64]]]:\n",
    "    W1, b1, W2, b2 = parameters['W1'], parameters['b1'], parameters['W2'], parameters['b2']\n",
    "    \n",
    "    # Layer 1\n",
    "    Z1: NDArray[float64] = X @ W1 + b1              # (N×2) × (2×2) + (1×2) = (N×2)\n",
    "    A1: NDArray[float64] = hidden_activation(Z1)  # (N×2)\n",
    "    \n",
    "    # Layer 2\n",
    "    Z2: NDArray[float64] = A1 @ W2 + b2             # (N×2) × (2×1) + (1×1) = (N×1)\n",
    "    A2: NDArray[float64] = output_activation(Z2)  # (N×1)\n",
    "    \n",
    "    cache: dict[str, NDArray[float64]] = {'Z1': Z1, 'A1': A1, 'Z2': Z2, 'A2': A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d884c",
   "metadata": {},
   "source": [
    "### Functions for loss computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac82af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(A2: NDArray[float64], Y: NDArray[float64]) -> float:\n",
    "    return float(np.mean((A2 - Y) ** 2))\n",
    "\n",
    "def compute_loss_derivative(A2: NDArray[float64], Y: NDArray[float64]) -> NDArray[float64]:\n",
    "    \"\"\"Derivative of 1/2 MSE loss: (A2 - Y)\"\"\"\n",
    "    return A2 - Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631648da",
   "metadata": {},
   "source": [
    "### Function implementing backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5806d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(\n",
    "    X: NDArray[float64], \n",
    "    Y: NDArray[float64], \n",
    "    cache: dict[str, NDArray[float64]], \n",
    "    parameters: dict[str, NDArray[float64]]\n",
    ") -> dict[str, NDArray[float64]]:\n",
    "    W2 = parameters['W2']\n",
    "    A1, A2 = cache['A1'], cache['A2']\n",
    "    \n",
    "    m: int = X.shape[0]  # batch size\n",
    "    \n",
    "    # Output layer gradients\n",
    "    dA2: NDArray[float64] = compute_loss_derivative(A2, Y)           # (m×1)\n",
    "    dZ2: NDArray[float64] = dA2 * output_activation_derivative(A2)      # (m×1)\n",
    "    dW2: NDArray[float64] = A1.T @ dZ2 / m                                # (2×m) × (m×1) = (2×1), averaged\n",
    "    db2: NDArray[float64] = np.sum(dZ2, axis=0, keepdims=True) / m      # (1×1), averaged\n",
    "    \n",
    "    # Hidden layer gradients\n",
    "    dA1: NDArray[float64] = dZ2 @ W2.T                                    # (m×1) × (1×2) = (m×2)\n",
    "    dZ1: NDArray[float64] = dA1 * hidden_activation_derivative(A1)      # (m×2)\n",
    "    dW1: NDArray[float64] = X.T @ dZ1 / m                                 # (2×m) × (m×2) = (2×2), averaged\n",
    "    db1: NDArray[float64] = np.sum(dZ1, axis=0, keepdims=True) / m      # (1×2), averaged\n",
    "    \n",
    "    gradients: dict[str, NDArray[float64]] = {'dW1': dW1, 'db1': db1, 'dW2': dW2, 'db2': db2}\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa153e9",
   "metadata": {},
   "source": [
    "### Function to update the parameters given the new gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda35efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(\n",
    "    parameters: dict[str, NDArray[float64]], \n",
    "    gradients: dict[str, NDArray[float64]], \n",
    "    learning_rate: float\n",
    ") -> dict[str, NDArray[float64]]:\n",
    "    parameters['W1'] -= learning_rate * gradients['dW1']\n",
    "    parameters['b1'] -= learning_rate * gradients['db1']\n",
    "    parameters['W2'] -= learning_rate * gradients['dW2']\n",
    "    parameters['b2'] -= learning_rate * gradients['db2']\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb2d37c",
   "metadata": {},
   "source": [
    "## Training and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f4df1",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04469dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(\n",
    "    X: NDArray[float64], \n",
    "    Y: NDArray[float64], \n",
    "    learning_rate: float = 0.1, \n",
    "    epochs: int = 1000,\n",
    "    input_size: int = 2,\n",
    "    hidden_size: int = 4,\n",
    "    output_size: int = 1,\n",
    ") -> tuple[dict[str, NDArray[float64]], list[float]]:\n",
    "    # Initialize parameters\n",
    "    parameters: dict[str, NDArray[float64]] = initialize_parameters(input_size, hidden_size, output_size)\n",
    "    \n",
    "    losses: list[float] = []\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        # Forward propagation\n",
    "        A2, cache = forward(X, parameters)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = compute_loss(A2, Y)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # Backward propagation\n",
    "        gradients = backward(X, Y, cache, parameters)\n",
    "        \n",
    "        # Update parameters\n",
    "        parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "    \n",
    "    return parameters, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd57441",
   "metadata": {},
   "source": [
    "### Prediction function using forward propagation with the parameters from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b3a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X: NDArray[float64], parameters: dict[str, NDArray[float64]]) -> NDArray[float64]:\n",
    "    return forward(X, parameters)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeed7dfa",
   "metadata": {},
   "source": [
    "## Visualization and Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f31a500",
   "metadata": {},
   "source": [
    "### Print the matrices containing the weights and the biases of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7319f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_matrices(parameters: dict[str, NDArray[float64]]) -> None:\n",
    "    for k, v in parameters.items():\n",
    "        rows: int\n",
    "        rows, _ = v.shape\n",
    "        \n",
    "        for r, vr in enumerate(v):\n",
    "            if rows == 1:\n",
    "                print(f'{k:2} = [ {\" \".join(f\"{vc:^9.5f}\" for vc in vr)} ]')\n",
    "                break\n",
    "            if r == 0:\n",
    "                print(f'{k:2} = ⎡ {\" \".join(f\"{vc:^9.5f}\" for vc in vr)} ⎤')\n",
    "            elif r == rows - 1:\n",
    "                print(f'{\" \":2}   ⎣ {\" \".join(f\"{vc:^9.5f}\" for vc in vr)} ⎦')\n",
    "            else:\n",
    "                print(f'{\" \":2}   ⎥ {\" \".join(f\"{vc:^9.5f}\" for vc in vr)} ⎥')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a86368",
   "metadata": {},
   "source": [
    "### Function for plotting the loss of the network throughout its training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(losses: list[float]) -> None:\n",
    "    \"\"\"Plot training loss over epochs\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(losses)\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title('Training Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabdf130",
   "metadata": {},
   "source": [
    "### Function for plotting the decision boundary of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(\n",
    "    basis_df: pd.DataFrame,\n",
    "    pair: tuple[str, str],\n",
    "    label: str,\n",
    "    parameters: dict[str, NDArray[float64]], \n",
    "    resolution: int = 500\n",
    ") -> None:\n",
    "    df = basis_df.copy()\n",
    "    \n",
    "    df[label] = basis_df[label].map({'M': 1, 'B': 0})\n",
    "    \n",
    "    X: NDArray[float64] = df[[pair[0], pair[1]]].values.astype(float64)\n",
    "    \n",
    "    m = df[[pair[0], pair[1]]].where(df[label] > 0.5)\n",
    "    b = df[[pair[0], pair[1]]].where(df[label] <= 0.5)\n",
    "    \n",
    "    # Create a grid of points\n",
    "    x_min: float64\n",
    "    x_max: float64\n",
    "    y_min: float64\n",
    "    y_max: float64\n",
    "    \n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, resolution),\n",
    "                         np.linspace(y_min, y_max, resolution))\n",
    "    \n",
    "    # Predict for each grid point\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    predictions = predict(grid_points, parameters)\n",
    "    predictions = predictions.reshape(xx.shape)\n",
    "    \n",
    "    # Plot decision boundary (where prediction = 0.5)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.contour(xx, yy, predictions, levels=[0.5], colors='black', linewidths=2)\n",
    "    plt.contourf(xx, yy, predictions, levels=25, alpha=0.3)\n",
    "    \n",
    "    # Plot data points\n",
    "    plt.scatter(m[pair[0]], m[pair[1]], c='red', edgecolors='black', label='Malignant (M)', s=50)\n",
    "    plt.scatter(b[pair[0]], b[pair[1]], c='blue', edgecolors='black', label='Benign (B)', s=50)\n",
    "    \n",
    "    plt.xlabel(pair[0])\n",
    "    plt.ylabel(pair[1])\n",
    "    plt.legend()\n",
    "    plt.title(f'Decision Boundary: {pair[0]} vs {pair[1]}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86991b2a",
   "metadata": {},
   "source": [
    "### Function for calculating the accuracy of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c559cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true: NDArray[float64], y_pred: NDArray[float64], threshold: float = 0.5) -> float:\n",
    "    # Convert probabilities to binary predictions\n",
    "    y_pred_binary: NDArray[float64] = (y_pred > threshold).astype(float64)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy: NDArray[float64] = (y_pred_binary == y_true)\n",
    "    \n",
    "    return float(np.mean(accuracy).astype(float64()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08235af5",
   "metadata": {},
   "source": [
    "### Funciton for printing the predictions from the prediction portion of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8312b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_predictions(\n",
    "    X_test: NDArray[float64], \n",
    "    test_predictions: NDArray[float64], \n",
    "    y_test: NDArray[float64], \n",
    "    diag_rev_map: dict[int, str]\n",
    ") -> None:\n",
    "    for i, (input, prediction, expected) in enumerate(zip(X_test, test_predictions, y_test)):\n",
    "        i_str = f'[{', '.join(f'{float(val):7.4f}' for val in input)}]'\n",
    "        p_str = f'{float(prediction.item()):.4f}'\n",
    "        m_str = f'{diag_rev_map[int(prediction.item() > 0.50)]}'\n",
    "        e_str = f'{diag_rev_map[int(expected.item())]}'\n",
    "        correct = '✓' if (prediction.item() > 0.50) == (expected.item() > 0.50) else '✗'\n",
    "        \n",
    "        print(f'{i+1:2d}. {i_str} -> {p_str} => {m_str} | {e_str} {correct}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c5ca4",
   "metadata": {},
   "source": [
    "## Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532408f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    # Seed for initial parameters\n",
    "    np.random.seed(67)\n",
    "    \n",
    "    # Read the dataset from the csv file\n",
    "    df = pd.read_csv('../data/wdbc.csv')\n",
    "    \n",
    "    # Set the chosen features\n",
    "    # In this case, they are 'concavity3' and 'radius3'\n",
    "    x1 = 'concavity3'\n",
    "    x2 = 'radius3'\n",
    "    \n",
    "    # Set the column name of the label\n",
    "    # In this case, it is 'Diagnosis'\n",
    "    y1 = 'Diagnosis'\n",
    "    \n",
    "    # Create the mappings for the diagnosis to binary values, and the reverse\n",
    "    diag_map = {'M': 1, 'B': 0}\n",
    "    diag_rev_map = {1: 'M', 0: 'B'}\n",
    "    \n",
    "    # Create the new dataframe of only the data columns to be used\n",
    "    selected_df: pd.DataFrame = df[[y1, x1, x2]]\n",
    "    \n",
    "    # Split the filtered dataframe into training dataset and testing dataset\n",
    "    # Here, 95% of the total dataset is used to train, while the remaining is used for prediction testing\n",
    "    train_df: pd.DataFrame = selected_df.sample(frac=0.95)\n",
    "    tests_df: pd.DataFrame = selected_df[~selected_df.index.isin(train_df.index)]\n",
    "    \n",
    "    # Transform the feature and label columns in to matrices for both the training and testing datasets\n",
    "    X_train: NDArray[float64] = train_df[[x1, x2]].values.astype(float64)\n",
    "    y_train: NDArray[float64] = train_df[y1].map(diag_map).to_numpy().astype(float64).reshape(-1, 1)\n",
    "    \n",
    "    X_test: NDArray[float64] = tests_df[[x1, x2]].values.astype(float64)\n",
    "    y_test: NDArray[float64] = tests_df[y1].map(diag_map).to_numpy().astype(float64).reshape(-1, 1)\n",
    "    \n",
    "    # Train the network and extract the parameters and loss for each epoch\n",
    "    parameters, losses = train_network(\n",
    "        X_train, y_train, learning_rate=0.05, epochs=1000,\n",
    "        input_size=2, hidden_size=3, output_size=1,\n",
    "    )\n",
    "    \n",
    "    # We print the matrices to see the values of the weights and biases\n",
    "    print_matrices(parameters)\n",
    "\n",
    "    # Plot the losses\n",
    "    plot_loss(losses)\n",
    "    \n",
    "    # Plot the decision boundary\n",
    "    plot_decision_boundary(\n",
    "        selected_df,\n",
    "        (x1, x2),\n",
    "        y1,\n",
    "        parameters,\n",
    "    )\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    test_predictions = predict(X_test, parameters)\n",
    "    \n",
    "    # Calculate training accuracy\n",
    "    train_predictions = predict(X_train, parameters)\n",
    "    train_accuracy = calculate_accuracy(y_train, train_predictions)\n",
    "    \n",
    "    # Calculate test accuracy\n",
    "    test_accuracy = calculate_accuracy(y_test, test_predictions)\n",
    "    \n",
    "    # Print the evaluation of the model based on its accuracy with the training data and its accuracy on the test data\n",
    "    print(f'\\n{' MODEL EVALUATION ':=^56}\\n')\n",
    "    print(f\"Training Accuracy: {train_accuracy:.2%}\")\n",
    "    print(f\"Test Accuracy:     {test_accuracy:.2%}\")\n",
    "    \n",
    "    # Print individual predictions from the test data\n",
    "    print(f'\\n{' PREDICTIONS ':=^56}\\n')\n",
    "    print_predictions(X_test, test_predictions, y_test, diag_rev_map)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
